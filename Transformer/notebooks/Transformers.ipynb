{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e827007f-92e6-410a-9e54-d6c6c4a0c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d577709d-0e0d-4780-b5c3-a44b13acdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(\n",
    "            torch.tensor(self.d_k, dtype=torch.float32, device=Q.device)\n",
    "        )\n",
    "        if mask is not None:\n",
    "            while mask.dim() < scores.dim():\n",
    "                mask = mask.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attn, V)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250bd6c1-0b82-4a27-a43b-9eb5f5abf939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model //num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = Q.size(0)\n",
    "\n",
    "        # 1. Linear projections: (batch, seq_len, d_model) → (batch, seq_len, num_heads * d_k)\n",
    "        Q = self.W_q(Q)\n",
    "        K = self.W_k(K)\n",
    "        V = self.W_v(V)\n",
    "\n",
    "         # 2. Split into heads: (batch, seq_len, num_heads, d_k)\n",
    "\n",
    "        Q = Q.view(batch_size , -1, self.num_heads, self.d_k).transpose(1,2)\n",
    "        K = K.view(batch_size, -1, self.num_heads , self.d_k).transpose(1,2)\n",
    "        V = V.view(batch_size, -1, self.num_heads , self.d_k).transpose(1,2)\n",
    "\n",
    "        # 3. Apply attention on each head\n",
    "        # Now Q, K, V: (batch, heads, seq_len, d_k)\n",
    "        \n",
    "        atten_output, atten_weights = self.attention(Q,K,V,mask = mask)\n",
    "\n",
    "        # 4. Concatenate heads\n",
    "        # (batch, heads, seq_len, d_k) → (batch, seq_len, d_model)\n",
    "        \n",
    "        concat =  atten_output.transpose(1,2).contiguous().view(batch_size , -1, self.d_model)\n",
    "\n",
    "        # 5. Final linear projection\n",
    "        \n",
    "        output = self.W_o(concat)\n",
    "\n",
    "        return output , atten_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57991da0-c19e-440f-911d-e673cd77d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model , d_ff , dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self,x):\n",
    "        return self.linear2(self.dropout(F.relu(self.linear1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edd7666-71b1-477f-bbe0-8742a9eef020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedForward(d_model , d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out, _ = self.attn(x,x,x,mask)\n",
    "        x = self.norm1(self.dropout1(attn_out))\n",
    "\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm2(x + self.dropout2(ffn_out))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbae1fa7-277b-44be-9945-b1076084413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, tgt_mask=None, memory_mask = None):\n",
    "        _x, _ = self.self_attn(x,x,x,tgt_mask)\n",
    "        x = self.norm1(x+self.dropout1(_x))\n",
    "\n",
    "        _x, _ = self.cross_attn(x,enc_out, enc_out, memory_mask)\n",
    "        x = self.norm2(x + self.dropout2(_x))\n",
    "\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.norm3(x+self.dropout3(ffn_out))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2d6de8-903c-4ef7-ad29-06678997e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, d_ff, \n",
    "                 num_encoder_layers, num_decoder_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.src_embed = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderBlock(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "        self.final_linear = nn.Linear(d_model, tgt_vocab_size)\n",
    "    def encode(self, src, src_mask=None):\n",
    "        x = self.pos_enc(self.src_embed(src))\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x\n",
    "    def decode(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
    "        x = self.pos_enc(self.tgt_embed(tgt))\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, memory, tgt_mask, memory_mask)\n",
    "        return x\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, memory_mask=None):\n",
    "        memory = self.encode(src, src_mask)\n",
    "        out = self.decode(tgt, memory, tgt_mask, memory_mask)\n",
    "        logits = self.final_linear(out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a264b85-ef71-4a1d-9349-aae521d82d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cdc55f4-297e-4b42-8f25-4fbfd609a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d13584-3e5a-4f5c-b653-a62b3f21f91e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('wmt14','de-en',split='train[:1%]')\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "MAX_LEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddea4943-c67d-4075-b97e-2c013b985dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'de': 'Wiederaufnahme der Sitzungsperiode', 'en': 'Resumption of the session'}}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6037af21-5609-4183-b681-1a47a91dad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    en_text = example['translation']['en']\n",
    "    de_text = example['translation']['de']\n",
    "\n",
    "    inputs = tokenizer(en_text, max_length=MAX_LEN, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    targets = tokenizer(de_text, max_length=MAX_LEN, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    return {\n",
    "        'src_input_ids': inputs.input_ids.squeeze(0),\n",
    "        'tgt_input_ids': targets.input_ids.squeeze(0)\n",
    "    }\n",
    "\n",
    "processed_dataset = dataset.map(preprocess,remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67db855d-4f8b-4520-9b80-0edd39c34962",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset.set_format(type=\"torch\", columns=[\"src_input_ids\", \"tgt_input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f39d6be-603b-44f0-9a85-c697d357d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "def collate_fn(batch):\n",
    "    src = torch.stack([item['src_input_ids'] for item in batch])\n",
    "    tgt = torch.stack([item['tgt_input_ids'] for item in batch])\n",
    "    return src,tgt\n",
    "\n",
    "train_loader = DataLoader(processed_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfa8714d-4651-45af-9c7b-b902534ce355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_src_mask(src):\n",
    "    mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "    return mask\n",
    "def create_tgt_mask(tgt):\n",
    "    batch_size, tgt_len = tgt.shape\n",
    "    pad_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)\n",
    "    subsequent_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()\n",
    "    subsequent_mask = subsequent_mask.unsqueeze(0).unsqueeze(1) \n",
    "    return pad_mask & subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90492f65-8eb5-4523-a3e9-87331ba7c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=tokenizer.vocab_size,\n",
    "    tgt_vocab_size=tokenizer.vocab_size,\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    d_ff=2048,\n",
    "    num_encoder_layers=6,\n",
    "    num_decoder_layers=6,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "434d8690-2498-4db3-89b0-9f93ca974291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████| 1409/1409 [06:33<00:00,  3.58it/s, loss=4.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished with loss: 4.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████████████████████████████████████████| 1409/1409 [06:34<00:00,  3.57it/s, loss=3.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished with loss: 3.7411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████████████████████████████████████████████████████| 1409/1409 [06:34<00:00,  3.57it/s, loss=3.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished with loss: 3.3754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████████████████████████████████████████████████████| 1409/1409 [06:35<00:00,  3.57it/s, loss=3.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 finished with loss: 3.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████████████████████████████████████████████████████| 1409/1409 [06:34<00:00,  3.57it/s, loss=2.91]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 finished with loss: 2.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for src, tgt in loop:\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        \n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "\n",
    "        src_mask = create_src_mask(src).to(device)\n",
    "        tgt_mask = create_tgt_mask(tgt_input).to(device)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "\n",
    "        logits = logits.reshape(-1, logits.size(-1))\n",
    "        tgt_output = tgt_output.reshape(-1)\n",
    "\n",
    "        loss = criterion(logits, tgt_output)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} finished with loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ad9f0-1749-40e3-af22-83aa503e37db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
